
name: ScanCode copyrights/authors (Docker, paged & parallel)

on:
  workflow_dispatch:
    inputs:
      components_file:
        description: "Path to input components JSON (default: input/components.json)"
        default: "input/components.json"
        required: true
        type: string
      page_size:
        description: "How many components to scan in parallel (page size)"
        default: 8
        required: true
        type: number
      scan_options:
        description: "ScanCode options (space-separated)"
        default: "--copyright --info"
        required: true
        type: string

jobs:
  prepare-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
      count: ${{ steps.count.outputs.count }}
      components_file: ${{ steps.echo.outputs.components_file }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Echo input path to outputs for reuse
        id: echo
        run: |
          echo "components_file=${{ github.event.inputs.components_file }}" >> "$GITHUB_OUTPUT"

      - name: Validate & read input components (dynamic path)
        id: build
        shell: bash
        run: |
          set -e
          INPUT="${{ github.event.inputs.components_file }}"
          if [ ! -f "$INPUT" ]; then
            echo "::error::Input file not found: $INPUT"
            exit 1
          fi
          # Build matrix entries from input (keep key fields to reconstruct later)
          MATRIX=$(jq -c '[ .[] | { 
              Component: .Component, 
              Url: .Url, 
              version: .version, 
              license: .license, 
              SNo: (."S.No") 
            } ]' "$INPUT")
          echo "matrix=$MATRIX" >> "$GITHUB_OUTPUT"

      - name: Count components
        id: count
        run: |
          INPUT="${{ github.event.inputs.components_file }}"
          COUNT=$(jq 'length' "$INPUT")
          echo "count=$COUNT" >> "$GITHUB_OUTPUT"

  build-image:
    runs-on: ubuntu-latest
    needs: prepare-matrix
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Clone ScanCode Toolkit (official)
        run: git clone --depth=1 https://github.com/aboutcode-org/scancode-toolkit.git
        # Docs (Docker option explained) [5](https://github.blog/news-insights/product-news/get-started-with-v4-of-github-actions-artifacts/)[6](https://eyindia-my.sharepoint.com/personal/bharath_n3_in_ey_com/Documents/Microsoft%20Copilot%20Chat%20Files/spdx-lite.json)

      - name: Build Docker image
        run: docker build -t scancode:latest scancode-toolkit

  scan-component:
    runs-on: ubuntu-latest
    needs: [prepare-matrix, build-image]
    strategy:
      fail-fast: false
      max-parallel: ${{ github.event.inputs.page_size }}
      matrix:
        include: ${{ fromJson(needs.prepare-matrix.outputs.matrix) }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Clone target repository
        if: ${{ matrix.Url != '' }}
        shell: bash
        run: |
          set -e
          git clone --depth=1 "${{ matrix.Url }}" repo || {
            echo "::warning::Clone failed for ${{ matrix.Url }}"; 
            mkdir -p repo; 
          }

      - name: Run ScanCode (Docker)
        shell: bash
        run: |
          set -e
          mkdir -p out
          docker run --rm -v "$PWD/repo":/scan scancode:latest \
            ${{ github.event.inputs.scan_options }} \
            --json-pp /scan_output.json /scan || true

          python - <<'PY'
          import json, os, glob
          comp = {
            "Component": os.environ.get("COMPONENT"),
            "version": os.environ.get("VERSION"),
            "Url": os.environ.get("URL"),
            "license": os.environ.get("LICENSE"),
            "S.No": int(os.environ.get("SNO", "0")),
          }
          copyrights, authors = set(), set()
          path = "/scan_output.json"
          if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
              data = json.load(f)
            for fi in data.get("files", []):
              for c in fi.get("copyrights", []):
                val = (c.get("value") or c.get("copyright") or "").strip()
                if val: copyrights.add(val)
              for a in fi.get("authors", []):
                val = (a.get("value") or a.get("author") or "").strip()
                if val: authors.add(val)
          comp["copyrights"] = sorted(copyrights)
          comp["authors"] = sorted(authors)
          os.makedirs("out", exist_ok=True)
          out_file = f'out/component-{comp["S.No"]}.json'
          with open(out_file, "w", encoding="utf-8") as f:
            json.dump(comp, f, indent=2)
          PY
        env:
          COMPONENT: ${{ matrix.Component }}
          VERSION:   ${{ matrix.version }}
          URL:       ${{ matrix.Url }}
          LICENSE:   ${{ matrix.license }}
          SNO:       ${{ matrix.SNo }}
        # Scan options reference (copyrights, authors via --copyright). [7](https://michaelheap.com/dynamic-matrix-generation-github-actions/)

      - name: Upload per-component artifact
        uses: actions/upload-artifact@v4
        with:
          name: component-${{ matrix.SNo }}-${{ matrix.Component }}
          path: out
        # v4 immediate availability & job scoping. [3](blob:https://m365.cloud.microsoft/dfd6401d-3874-43c4-8572-9a60ca23e79c)

  aggregate:
    runs-on: ubuntu-latest
    needs: scan-component
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all component artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: component-*
          merge-multiple: true

      - name: Merge back into original list (dynamic input path)
        id: merge
        shell: bash
        run: |
          set -e
          INPUT="${{ needs.prepare-matrix.outputs.components_file }}"
          python - <<'PY'
          import json, glob, os
          inp = os.environ["INPUT"]
          with open(inp, "r", encoding="utf-8") as f:
            components = json.load(f)

          enriched = {}
          for path in glob.glob("**/component-*.json", recursive=True):
            with open(path, "r", encoding="utf-8") as f:
              obj = json.load(f)
              enriched[obj["S.No"]] = obj

          out = []
          for item in components:
            sno = item.get("S.No")
            add = enriched.get(sno, {})
            merged = dict(item)
            merged["copyrights"] = add.get("copyrights", [])
            merged["authors"]    = add.get("authors", [])
            out.append(merged)

          base, ext = os.path.splitext(inp)
          final_name = f"{base}-with-copyrights-{len(out)}{ext or '.json'}"
          with open(final_name, "w", encoding="utf-8") as f:
            json.dump(out, f, indent=2)
          print(final_name)
          PY
        env:
          INPUT: ${{ needs.prepare-matrix.outputs.components_file }}

      - name: Upload aggregated JSON
        uses: actions/upload-artifact@v4
        with:
          name: components-with-copyrights
